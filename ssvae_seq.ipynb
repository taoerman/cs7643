{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f621be3c-6850-458f-8471-507e745e9c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from numpy.lib.stride_tricks import sliding_window_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a2b7877-a04e-4c24-b7f7-583f26a23064",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load(\"train_split.npy\", allow_pickle=True).item()\n",
    "val = np.load(\"val_split.npy\", allow_pickle=True).item()\n",
    "test = np.load(\"test-release.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba12de8-2cf3-4d4e-95ba-2a60fa727d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_previous_frames(x, num_frames):\n",
    "    if num_frames == 1:\n",
    "        return x\n",
    "    B, D = x.shape\n",
    "    pad = np.zeros((num_frames - 1, D))\n",
    "    padded = np.vstack([pad, x])\n",
    "    windows = sliding_window_view(padded, window_shape=(num_frames, D)).squeeze(axis=1)\n",
    "    return windows.reshape(B, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68bdea60-d338-4af6-b93f-ee39d18617fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames_per_cls = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "416beb0d-87af-4836-90b1-a0fcf2ee54c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([426635, 280]), torch.Size([426635]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_x = np.concatenate([seq[\"keypoints\"] for seq in train[\"sequences\"].values()], axis=0)\n",
    "labeled_x = attach_previous_frames(labeled_x.reshape(-1, 28), num_frames_per_cls)\n",
    "labeled_x = torch.tensor(labeled_x)\n",
    "y = np.concatenate([seq[\"annotations\"] for seq in train[\"sequences\"].values()], axis=0)\n",
    "y = torch.tensor(y)\n",
    "labeled_x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e997eebc-f55d-4b88-ade6-7319e905e029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8168491, 280])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_x = np.concatenate([seq[\"keypoints\"] for seq in test[\"sequences\"].values()], axis=0)\n",
    "unlabeled_x = attach_previous_frames(unlabeled_x.reshape(-1, 28), num_frames_per_cls)\n",
    "unlabeled_x = torch.tensor(unlabeled_x)\n",
    "unlabeled_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15a20e52-9e88-4af3-a306-0d8f37d2587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "std, mean = torch.std_mean(torch.cat((labeled_x, unlabeled_x), dim=0), dim=0)\n",
    "labeled_x = (labeled_x - mean) / std\n",
    "unlabeled_x = (unlabeled_x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07440027-91e1-4dda-9c45-d9b66819cd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([81103, 280]), torch.Size([81103]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x = np.concatenate([seq[\"keypoints\"] for seq in val[\"sequences\"].values()], axis=0)\n",
    "val_x = attach_previous_frames(val_x.reshape(-1, 28), num_frames_per_cls)\n",
    "val_x = torch.tensor(val_x)\n",
    "val_x = (val_x - mean) / std\n",
    "val_y = np.concatenate([seq[\"annotations\"] for seq in val[\"sequences\"].values()], axis=0)\n",
    "val_y = torch.tensor(val_y)\n",
    "val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b52e8a8c-4abb-4967-95d1-1f2bf4a10cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_parameters(h, dim=-1):\n",
    "    m, h = torch.split(h, h.size(dim) // 2, dim=dim)\n",
    "    v = F.softplus(h) + 1e-8\n",
    "    return m, v\n",
    "\n",
    "def sample_gaussian(m, v):\n",
    "    unit_sample = torch.normal(torch.zeros(m.shape), torch.ones(v.shape)).to(device)\n",
    "    z = m + torch.sqrt(v) * unit_sample\n",
    "    return z\n",
    "\n",
    "def kl_cat(q, log_q, log_p):\n",
    "    element_wise = (q * (log_q - log_p))\n",
    "    kl = element_wise.sum(-1)\n",
    "    return kl\n",
    "\n",
    "def kl_normal(qm, qv, pm, pv):\n",
    "    element_wise = 0.5 * (torch.log(pv) - torch.log(qv) + qv / pv + (qm - pm).pow(2) / pv - 1)\n",
    "    kl = element_wise.sum(-1)\n",
    "    return kl\n",
    "\n",
    "def log_normal(x, m, v):\n",
    "    log_prob = -0.5 * (torch.log(v) + (x - m).pow(2) / v + np.log(2 * np.pi))\n",
    "    log_prob = log_prob.sum(-1)\n",
    "    return log_prob\n",
    "\n",
    "def duplicate(x, rep):\n",
    "    return x.expand(rep, *x.shape).reshape(-1, *x.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "193d17e1-1bd2-465b-b30c-621675a5adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim, y_dim):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(28 * num_frames_per_cls + y_dim, 128),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(128, 2 * z_dim),\n",
    "        )\n",
    "\n",
    "    def encode(self, x, y):\n",
    "        xy = torch.cat((x, y), dim=1)\n",
    "        h = self.net(xy)\n",
    "        m, v = gaussian_parameters(h, dim=1)\n",
    "        return m, v\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, y_dim):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(z_dim + y_dim, 128),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(128, 28 * num_frames_per_cls)\n",
    "        )\n",
    "\n",
    "    def decode(self, z, y):\n",
    "        zy = torch.cat((z, y), dim=1)\n",
    "        return self.net(zy)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, y_dim):\n",
    "        super().__init__()\n",
    "        self.y_dim = y_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(28 * num_frames_per_cls, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, y_dim)\n",
    "        )\n",
    "\n",
    "    def classify(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19b6530f-2f33-48ce-9da8-439b88b4bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSVAE(nn.Module):\n",
    "    def __init__(self, gen_weight=1, class_weight=100):\n",
    "        super().__init__()\n",
    "        self.z_dim = 64\n",
    "        self.y_dim = 4\n",
    "        self.gen_weight = gen_weight\n",
    "        self.class_weight = class_weight\n",
    "        self.enc = Encoder(self.z_dim, self.y_dim)\n",
    "        self.dec = Decoder(self.z_dim, self.y_dim)\n",
    "        self.cls = Classifier(self.y_dim)\n",
    "\n",
    "        # Set prior as fixed parameter attached to Module\n",
    "        self.z_prior_m = torch.nn.Parameter(torch.zeros(1), requires_grad=False)\n",
    "        self.z_prior_v = torch.nn.Parameter(torch.ones(1), requires_grad=False)\n",
    "\n",
    "    def negative_elbo_bound(self, x):\n",
    "        y_logits = self.cls.classify(x)\n",
    "        y_logprob = F.log_softmax(y_logits, dim=1)\n",
    "        y_prob = torch.softmax(y_logprob, dim=1) # (batch, y_dim)\n",
    "\n",
    "        # Duplicate y based on x's batch size. Then duplicate x\n",
    "        # This enumerates all possible combination of x with labels (0, 1, 2, 3)\n",
    "        y = np.repeat(np.arange(self.y_dim), x.size(0))\n",
    "        y = x.new(np.eye(self.y_dim)[y])\n",
    "        x = duplicate(x, self.y_dim)\n",
    "\n",
    "        z_m, z_v = self.enc.encode(x, y)\n",
    "        z = sample_gaussian(z_m, z_v)\n",
    "        x_m = self.dec.decode(z, y)\n",
    "        x_v = torch.tensor(0.1).repeat(x_m.shape).to(device)\n",
    "\n",
    "        kl_y = kl_cat(y_prob, y_logprob, np.log(1.0 / self.y_dim))\n",
    "        kl_z = kl_normal(z_m, z_v, self.z_prior_m, self.z_prior_v)\n",
    "        kl_z = (kl_z.reshape(self.y_dim, -1) * y_prob.t()).sum(dim=0)\n",
    "        rec = -log_normal(x, x_m, x_v)\n",
    "        rec = (rec.reshape(self.y_dim, -1) * y_prob.t()).sum(dim=0)\n",
    "        nelbo = kl_y + kl_z + rec\n",
    "\n",
    "        nelbo, kl_z, kl_y, rec = nelbo.mean(), kl_z.mean(), kl_y.mean(), rec.mean()\n",
    "        return nelbo, kl_z, kl_y, rec\n",
    "\n",
    "    def classification_cross_entropy(self, x, y):\n",
    "        y_logits = self.cls.classify(x)\n",
    "        return F.cross_entropy(y_logits, y.argmax(1))\n",
    "\n",
    "    def loss(self, x, xl, yl):\n",
    "        if self.gen_weight > 0:\n",
    "            nelbo, kl_z, kl_y, rec = self.negative_elbo_bound(x)\n",
    "        else:\n",
    "            nelbo, kl_z, kl_y, rec = [0] * 4\n",
    "        ce = self.classification_cross_entropy(xl, yl)\n",
    "        loss = self.gen_weight * nelbo + self.class_weight * ce\n",
    "\n",
    "        summaries = dict((\n",
    "            ('train/loss', loss),\n",
    "            ('class/ce', ce),\n",
    "            ('gen/elbo', -nelbo),\n",
    "            ('gen/kl_z', kl_z),\n",
    "            ('gen/kl_y', kl_y),\n",
    "            ('gen/rec', rec),\n",
    "        ))\n",
    "\n",
    "        return loss, summaries\n",
    "\n",
    "    def compute_sigmoid_given(self, z, y):\n",
    "        logits = self.dec.decode(z, y)\n",
    "        return torch.sigmoid(logits)\n",
    "\n",
    "    def sample_z(self, batch):\n",
    "        return ut.sample_gaussian(self.z_prior[0].expand(batch, self.z_dim),\n",
    "                                  self.z_prior[1].expand(batch, self.z_dim))\n",
    "\n",
    "    def sample_x_given(self, z, y):\n",
    "        return torch.bernoulli(self.compute_sigmoid_given(z, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7841568-f5ca-414b-95f9-e8075f7c10d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "device = \"cuda\"\n",
    "labeled_batch_size = 64\n",
    "unlabeled_batch_size = 320\n",
    "learning_rate = 1e-3\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a39aff5-6794-4531-9c47-a3b3b044e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed);\n",
    "labeled_dataset = TensorDataset(labeled_x, y)\n",
    "unlabeled_dataset = TensorDataset(unlabeled_x)\n",
    "labeled_loader = DataLoader(labeled_dataset, batch_size=labeled_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a58eebe8-3181-495c-86de-528653ae64e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SSVAE(gen_weight=0).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a138b10a-a9c3-4b86-bbc4-01f920ff008a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss=141.3575\n",
      "Train_loss=38.6211\n",
      "Train_loss=35.8927\n",
      "Epoch 0, Train-F1=0.6874, Val-F1=0.5539\n",
      "Train_loss=17.6223\n",
      "Train_loss=30.6116\n",
      "Train_loss=29.9602\n",
      "Epoch 1, Train-F1=0.7447, Val-F1=0.5528\n",
      "Train_loss=27.4175\n",
      "Train_loss=27.9577\n",
      "Train_loss=27.5408\n",
      "Epoch 2, Train-F1=0.7720, Val-F1=0.5689\n",
      "Train_loss=16.4001\n",
      "Train_loss=26.1178\n",
      "Train_loss=25.9384\n",
      "Epoch 3, Train-F1=0.7822, Val-F1=0.5175\n",
      "Train_loss=24.8212\n",
      "Train_loss=24.8936\n",
      "Train_loss=24.7009\n",
      "Epoch 4, Train-F1=0.7714, Val-F1=0.5335\n",
      "Train_loss=19.8337\n",
      "Train_loss=23.7141\n",
      "Train_loss=23.7532\n",
      "Epoch 5, Train-F1=0.8136, Val-F1=0.5702\n",
      "Train_loss=29.4009\n",
      "Train_loss=22.7871\n",
      "Train_loss=22.8677\n",
      "Epoch 6, Train-F1=0.7995, Val-F1=0.4858\n",
      "Train_loss=20.3117\n",
      "Train_loss=22.3570\n",
      "Train_loss=22.1598\n",
      "Epoch 7, Train-F1=0.8256, Val-F1=0.5431\n",
      "Train_loss=18.9684\n",
      "Train_loss=21.5382\n",
      "Train_loss=21.5264\n",
      "Epoch 8, Train-F1=0.8193, Val-F1=0.5411\n",
      "Train_loss=28.0795\n",
      "Train_loss=21.0183\n",
      "Train_loss=20.9491\n",
      "Epoch 9, Train-F1=0.8365, Val-F1=0.5007\n",
      "Train_loss=20.4425\n",
      "Train_loss=20.3716\n",
      "Train_loss=20.4350\n",
      "Epoch 10, Train-F1=0.8305, Val-F1=0.5200\n",
      "Train_loss=25.9680\n",
      "Train_loss=19.9999\n",
      "Train_loss=20.0233\n",
      "Epoch 11, Train-F1=0.8262, Val-F1=0.5195\n",
      "Train_loss=16.0374\n",
      "Train_loss=19.6349\n",
      "Train_loss=19.5041\n",
      "Epoch 12, Train-F1=0.8516, Val-F1=0.5446\n",
      "Train_loss=11.8646\n",
      "Train_loss=19.1508\n",
      "Train_loss=19.1521\n",
      "Epoch 13, Train-F1=0.8479, Val-F1=0.4860\n",
      "Train_loss=42.0772\n",
      "Train_loss=18.7996\n",
      "Train_loss=18.8060\n",
      "Epoch 14, Train-F1=0.8572, Val-F1=0.4576\n",
      "Train_loss=19.2025\n",
      "Train_loss=18.4944\n",
      "Train_loss=18.4422\n",
      "Epoch 15, Train-F1=0.8623, Val-F1=0.5017\n",
      "Train_loss=15.3291\n",
      "Train_loss=17.9671\n",
      "Train_loss=18.1261\n",
      "Epoch 16, Train-F1=0.8575, Val-F1=0.4893\n",
      "Train_loss=38.8042\n",
      "Train_loss=17.6773\n",
      "Train_loss=17.7590\n",
      "Epoch 17, Train-F1=0.8587, Val-F1=0.5126\n",
      "Train_loss=7.6255\n",
      "Train_loss=17.4197\n",
      "Train_loss=17.5646\n",
      "Epoch 18, Train-F1=0.8678, Val-F1=0.4959\n",
      "Train_loss=15.0704\n",
      "Train_loss=17.1964\n",
      "Train_loss=17.2277\n",
      "Epoch 19, Train-F1=0.8640, Val-F1=0.5406\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    total_count = 0\n",
    "    for i, (xl, yl) in enumerate(labeled_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        unlabeled_indices = torch.randint(0, len(unlabeled_dataset), (unlabeled_batch_size,))\n",
    "        xu = unlabeled_dataset[unlabeled_indices][0]\n",
    "\n",
    "        xu = xu.to(device).float()\n",
    "        yl = yl.new(np.eye(4)[yl]).to(device).float()\n",
    "        xl = xl.to(device).float()\n",
    "        loss, summaries = model.loss(xu, xl, yl)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.detach().item() * len(xl)\n",
    "        total_count += len(xl)\n",
    "\n",
    "        if i % 3000 == 0:\n",
    "            print(f\"Train_loss={total_loss / total_count:.4f}\")\n",
    "\n",
    "    train_pred = model.cls.classify(labeled_x.to(device).float()).argmax(1)\n",
    "    train_f1 = f1_score(y, train_pred.cpu(), average=\"macro\", labels=[0, 1, 2])\n",
    "    val_pred = model.cls.classify(val_x.to(device).float()).argmax(1)\n",
    "    val_f1 = f1_score(val_y, val_pred.cpu(), average=\"macro\", labels=[0, 1, 2])\n",
    "\n",
    "    print(f\"Epoch {epoch}, Train-F1={train_f1:.4f}, Val-F1={val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8440e6f-1165-4c8f-a848-9e023a535134",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SSVAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6402128e-015a-484f-a6ec-17a867190b6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss=1575.3906\n",
      "Train_loss=32.9907\n",
      "Train_loss=20.4748\n",
      "Epoch 0, Train-F1=0.6804, Val-F1=0.5475\n",
      "Train_loss=4.6729\n",
      "Train_loss=4.4974\n",
      "Train_loss=3.4594\n",
      "Epoch 1, Train-F1=0.7180, Val-F1=0.5439\n",
      "Train_loss=4.6663\n",
      "Train_loss=0.7796\n",
      "Train_loss=0.2835\n",
      "Epoch 2, Train-F1=0.7568, Val-F1=0.5276\n",
      "Train_loss=11.3763\n",
      "Train_loss=-1.7113\n",
      "Train_loss=-2.0872\n",
      "Epoch 3, Train-F1=0.7788, Val-F1=0.4970\n",
      "Train_loss=-2.3672\n",
      "Train_loss=-3.5126\n",
      "Train_loss=-3.7839\n",
      "Epoch 4, Train-F1=0.7886, Val-F1=0.5842\n",
      "Train_loss=-9.9792\n",
      "Train_loss=-4.9361\n",
      "Train_loss=-5.2442\n",
      "Epoch 5, Train-F1=0.8024, Val-F1=0.5250\n",
      "Train_loss=-15.8496\n",
      "Train_loss=-6.1993\n",
      "Train_loss=-6.2841\n",
      "Epoch 6, Train-F1=0.8099, Val-F1=0.5327\n",
      "Train_loss=7.3044\n",
      "Train_loss=-7.0621\n",
      "Train_loss=-7.1523\n",
      "Epoch 7, Train-F1=0.8138, Val-F1=0.5611\n",
      "Train_loss=-7.7760\n",
      "Train_loss=-7.7542\n",
      "Train_loss=-7.9260\n",
      "Epoch 8, Train-F1=0.8185, Val-F1=0.5486\n",
      "Train_loss=3.4565\n",
      "Train_loss=-8.5334\n",
      "Train_loss=-8.6773\n",
      "Epoch 9, Train-F1=0.8278, Val-F1=0.5319\n",
      "Train_loss=-8.7251\n",
      "Train_loss=-9.2312\n",
      "Train_loss=-9.2385\n",
      "Epoch 10, Train-F1=0.8323, Val-F1=0.4884\n",
      "Train_loss=-12.7255\n",
      "Train_loss=-9.8714\n",
      "Train_loss=-9.8308\n",
      "Epoch 11, Train-F1=0.8352, Val-F1=0.5172\n",
      "Train_loss=7.6595\n",
      "Train_loss=-10.2372\n",
      "Train_loss=-10.3464\n",
      "Epoch 12, Train-F1=0.8425, Val-F1=0.5390\n",
      "Train_loss=-13.5938\n",
      "Train_loss=-10.5382\n",
      "Train_loss=-10.6361\n",
      "Epoch 13, Train-F1=0.8401, Val-F1=0.5130\n",
      "Train_loss=1.6103\n",
      "Train_loss=-10.9998\n",
      "Train_loss=-11.0313\n",
      "Epoch 14, Train-F1=0.8483, Val-F1=0.5267\n",
      "Train_loss=-8.9249\n",
      "Train_loss=-11.4110\n",
      "Train_loss=-11.5103\n",
      "Epoch 15, Train-F1=0.8578, Val-F1=0.5487\n",
      "Train_loss=-14.7589\n",
      "Train_loss=-11.7881\n",
      "Train_loss=-11.7771\n",
      "Epoch 16, Train-F1=0.8623, Val-F1=0.5456\n",
      "Train_loss=-18.6117\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m yl \u001b[38;5;241m=\u001b[39m yl\u001b[38;5;241m.\u001b[39mnew(np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m4\u001b[39m)[yl])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     12\u001b[0m xl \u001b[38;5;241m=\u001b[39m xl\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 13\u001b[0m loss, summaries \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[11], line 48\u001b[0m, in \u001b[0;36mSSVAE.loss\u001b[0;34m(self, x, xl, yl)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, xl, yl):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen_weight \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 48\u001b[0m         nelbo, kl_z, kl_y, rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_elbo_bound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m         nelbo, kl_z, kl_y, rec \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m\n",
      "Cell \u001b[0;32mIn[11], line 30\u001b[0m, in \u001b[0;36mSSVAE.negative_elbo_bound\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m z \u001b[38;5;241m=\u001b[39m sample_gaussian(z_m, z_v)\n\u001b[1;32m     29\u001b[0m x_m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec\u001b[38;5;241m.\u001b[39mdecode(z, y)\n\u001b[0;32m---> 30\u001b[0m x_v \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_m\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m kl_y \u001b[38;5;241m=\u001b[39m kl_cat(y_prob, y_logprob, np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_dim))\n\u001b[1;32m     33\u001b[0m kl_z \u001b[38;5;241m=\u001b[39m kl_normal(z_m, z_v, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_prior_m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_prior_v)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    total_count = 0\n",
    "    for i, (xl, yl) in enumerate(labeled_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        unlabeled_indices = torch.randint(0, len(unlabeled_dataset), (unlabeled_batch_size,))\n",
    "        xu = unlabeled_dataset[unlabeled_indices][0]\n",
    "\n",
    "        xu = xu.to(device).float()\n",
    "        yl = yl.new(np.eye(4)[yl]).to(device).float()\n",
    "        xl = xl.to(device).float()\n",
    "        loss, summaries = model.loss(xu, xl, yl)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.detach().item() * len(xl)\n",
    "        total_count += len(xl)\n",
    "\n",
    "        if i % 3000 == 0:\n",
    "            print(f\"Train_loss={total_loss / total_count:.4f}\")\n",
    "\n",
    "    train_pred = model.cls.classify(labeled_x.to(device).float()).argmax(1)\n",
    "    train_f1 = f1_score(y, train_pred.cpu(), average=\"macro\", labels=[0, 1, 2])\n",
    "    val_pred = model.cls.classify(val_x.to(device).float()).argmax(1)\n",
    "    val_f1 = f1_score(val_y, val_pred.cpu(), average=\"macro\", labels=[0, 1, 2])\n",
    "\n",
    "    print(f\"Epoch {epoch}, Train-F1={train_f1:.4f}, Val-F1={val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b280d4-0487-41c5-a782-c4d271e0f977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
